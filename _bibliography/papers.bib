---
---

@phdthesis{lopezbrau2023social,
  title={The Social Representation of the Physical World},
  school={Yale University},
  author={Lopez-Brau, Michael},
  year={2023},
  note={PhD dissertation},
  pdf={dissertation.pdf},
  abbr={Dissertation}
}

@article{lopezbrau2023people,
  title={People can use the placement of objects to infer communicative goals},
  author={Lopez-Brau, Michael and Jara-Ettinger, Julian},
  year={2023},
  journal={Cognition},
  volume={239},
  pages={105524},
  publisher={Elsevier},
  doi={https://doi.org/10.1016/j.cognition.2023.105524},
  abstract={Beyond words and gestures, people have a remarkable capacity to communicate indirectly through everyday objects: A hat on a chair can mean it is occupied, rope hanging across an entrance can mean we should not cross, and objects placed in a closed box can imply they are not ours to take. How do people generate and interpret the communicative meaning of objects? We hypothesized that this capacity is supported by social goal inference, where observers recover what social goal explains an object being placed in a particular location. To test this idea, we study a category of common ad-hoc communicative objects where a small cost is used to signal avoidance. Using computational modeling, we first show that goal inference from indirect physical evidence can give rise to the ability to use object placement to communicate. We then show that people from the U.S. and the Tsimane'—a farming-foraging group native to the Bolivian Amazon—can infer the communicative meaning of object placement in the absence of a pre-existing convention, and that people's inferences are quantitatively predicted by our model. Finally, we show evidence that people can store and retrieve this meaning for use in subsequent encounters, revealing a potential mechanism for how ad-hoc communicative objects become quickly conventionalized. Our model helps shed light on how humans use their ability to interpret other people's behavior to embed social meaning into the physical world.},
  bibtex_show={true},
  selected={true},
  pdf={Lopez-Brau & Jara-Ettinger (2023).pdf},
  supp={https://osf.io/57n4g},
  abbr={Cognition}
}

@article{lopezbrau2022social,
  title={Social inferences from physical evidence via Bayesian event reconstruction},
  author={Lopez-Brau, Michael and Kwon, Joseph and Jara-Ettinger, Julian},
  year={2022},
  journal={Journal of Experimental Psychology: General},
  volume={151},
  issue={9},
  pages={2029--2042},
  publisher={American Psychological Association},
  doi={https://psycnet.apa.org/doi/10.1037/xge0001182},
  abstract={Humans can make remarkable social inferences by watching each other's behavior. In many cases, however, people can also make social inferences about agents whose behavior they cannot see, based only on the physical evidence left behind. We hypothesized that this capacity is supported by a form of mental event reconstruction. Under this account, observers derive social inferences by reconstructing the agent's behavior, based on the physical evidence that revealed their presence. We present a computational model of this idea, embedded in a Bayesian framework for action understanding, and show that its predictions match human inferences with high quantitative accuracy. Specifically, Experiment 1 shows that people can infer where an agent came from and which goal they pursued in a room, all from a small pile of cookie crumbs. Experiment 2 shows that people can explicitly reconstruct the actions that the agent took, and these reconstructed trajectories can predict the entry point and goal inferences from Experiment 1. Finally, Experiment 3 shows that people can also infer whether one or two agents were in a room based on the position of two piles of cookie crumbs. Our results shed light on how people extract social information from the physical world.},
  bibtex_show={true},
  selected={true},
  pdf={Lopez-Brau et al. (2022).pdf},
  supp={https://osf.io/q3ct5},
  abbr={JEP:G}
}

@article{lopezbrau2021attentional,
  title={Attentional prioritization for historical traces of agency},
  author={Lopez-Brau, Michael and Colombatto, Clara and Jara-Ettinger, Julian and Scholl, Brian},
  year={2021},
  journal={Journal of Vision},
  volume={21},
  issue={9},
  pages={2748--2748},
  publisher={The Association for Research in Vision and Ophthalmology},
  doi={https://doi.org/10.1167/jov.21.9.2748},
  abstract={Among the most important stimuli we can perceive are other agents. Accordingly, a great deal of work has shown how visual attention is prioritized not just for certain lower-level properties (e.g. brightness or motion) but also for *social* stimuli (e.g. our impressive efficiency at detecting the presence of people in natural scenes). In nearly all such work, the relevant agents are explicitly visible — e.g. in the form of bodies, faces, or eyes. But we can also readily perceive the *historical traces* that agents may leave behind. When walking along a hiking trail, for example, a stack of rocks along the side of the path may elicit the immediate strong impression that an agent had been present, since such configurations are exceptionally unlikely to be produced by natural processes. Does visual processing also prioritize such 'traces of agency' (independent from properties such as order and complexity)? We explored this using visual search, in scenes filled with two kinds of block towers. In Agentic Trace towers, the blocks were slightly misaligned (as would only likely occur if they had been intentionally stacked by an agent), while in Non-Agentic towers they were perfectly stacked (in ways an agent would be unlikely to achieve). Across multiple experiments, observers were both faster and more accurate at detecting Agentic Trace towers (in arrays of Non-Agentic towers), compared to detecting Non-Agentic towers (in arrays of Agentic Trace towers). Critically, this difference was stronger than when the same stimuli were presented in ways that equated order and complexity (e.g. with additional vertical spacing), while eliminating perceived traces of agency. This attentional prioritization for "agency without agents" reveals that social perception is not just a response to the superficial appearances of agents themselves, but also to the deeper and subtler traces that they leave in the world.},
  bibtex_show={true},
  selected={false},
  abbr={VSS}
}

@article{jacobs2021what,
  title={What happened here? Children integrate physical reasoning to infer actions from indirect evidence},
  author={Jacobs, Colin and Lopez-Brau, Michael and Jara-Ettinger, Julian},
  year={2021},
  journal={Proceedings of the 43rd Annual Meeting of the Cognitive Science Society},
  volume={43},
  doi={https://doi.org/10.1016/j.cognition.2023.105524},
  abstract={As we navigate through the world, we often leave traces of our actions: a broken branch, a footprint in the mud, a dirty coffee mug at a desk. As observers, these traces enable us to make surprisingly complex social inferences about the actions that may have caused them: what the other person may have been doing, what their likely goals were, and more. But how might a conspicuous lack of evidence prompt similar reasoning? We hypothesize that children consider the presence and absence of physical evidence to infer possible prior actions and their outcomes. To test this hypothesis, we ask children to infer which of two bowls (each containing different materials) was acted upon without witnessing the action directly. In support of this proposal, we found that children readily reconstruct an agent's actions after observing indirect evidence. Importantly, they are also able to use the difficulty of concealing such evidence to interpret its absence.},
  bibtex_show={true},
  selected={false},
  pdf={Jacobs et al. (2021).pdf},
  abbr={CogSci}
}